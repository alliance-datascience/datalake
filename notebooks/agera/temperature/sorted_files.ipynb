{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec722503-2e13-478c-a70a-a1246af9b8c1",
   "metadata": {},
   "source": [
    "## Sorted temperature folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "408a65f2-ab15-487e-a3eb-a86879008be3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "920e9407-495a-42ca-93a5-ea4b7d333df6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analizar_nombres_archivos(directorio):\n",
    "    # Modificamos el patrón para aceptar versiones con uno o más dígitos después del punto\n",
    "    patron = re.compile(r'^(Temperature-Air-2m-(?:Min|Mean|Max)-24h)_(C3S-glob-agric)_(AgERA5)_(\\d{8})_(final-v\\d+\\.\\d+(?:\\.\\d+)?)\\.nc$')\n",
    "    \n",
    "    archivos = [f for f in os.listdir(directorio) if f.endswith('.nc')]\n",
    "    \n",
    "    resultados = {\n",
    "        'total_archivos': len(archivos),\n",
    "        'archivos_validos': 0,\n",
    "        'archivos_invalidos': [],\n",
    "        'tipos_temperatura': defaultdict(int),\n",
    "        'versiones': defaultdict(int),\n",
    "        'fechas': defaultdict(lambda: {'count': 0, 'tipos': set()}),\n",
    "        'fechas_faltantes': set(),\n",
    "        'fechas_incompletas': [],\n",
    "        'fechas_duplicadas': [],\n",
    "        'fecha_inicio': None,\n",
    "        'fecha_fin': None\n",
    "    }\n",
    "    \n",
    "    todas_las_fechas = set()\n",
    "    \n",
    "    for archivo in archivos:\n",
    "        match = patron.match(archivo)\n",
    "        if match:\n",
    "            resultados['archivos_validos'] += 1\n",
    "            tipo_temp, _, _, fecha, version = match.groups()\n",
    "            \n",
    "            fecha_dt = datetime.strptime(fecha, \"%Y%m%d\")\n",
    "            if resultados['fecha_inicio'] is None or fecha_dt < resultados['fecha_inicio']:\n",
    "                resultados['fecha_inicio'] = fecha_dt\n",
    "            if resultados['fecha_fin'] is None or fecha_dt > resultados['fecha_fin']:\n",
    "                resultados['fecha_fin'] = fecha_dt\n",
    "            \n",
    "            resultados['tipos_temperatura'][tipo_temp] += 1\n",
    "            resultados['versiones'][version] += 1\n",
    "            resultados['fechas'][fecha]['count'] += 1\n",
    "            resultados['fechas'][fecha]['tipos'].add(tipo_temp)\n",
    "            \n",
    "            todas_las_fechas.add(fecha)\n",
    "            \n",
    "            if resultados['fechas'][fecha]['count'] > 3:\n",
    "                resultados['fechas_duplicadas'].append(fecha)\n",
    "        else:\n",
    "            resultados['archivos_invalidos'].append(archivo)\n",
    "    \n",
    "    # Verificar fechas faltantes e incompletas\n",
    "    if resultados['fecha_inicio'] and resultados['fecha_fin']:\n",
    "        fecha_actual = resultados['fecha_inicio']\n",
    "        while fecha_actual <= resultados['fecha_fin']:\n",
    "            fecha_str = fecha_actual.strftime(\"%Y%m%d\")\n",
    "            if fecha_str not in todas_las_fechas:\n",
    "                resultados['fechas_faltantes'].add(fecha_str)\n",
    "            elif len(resultados['fechas'][fecha_str]['tipos']) < 3:\n",
    "                resultados['fechas_incompletas'].append(fecha_str)\n",
    "            fecha_actual += timedelta(days=1)\n",
    "    \n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3609115-fe0d-4249-b594-764d581e2cce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def imprimir_informe(resultados):\n",
    "    print(f\"Informe de análisis de nombres de archivos:\")\n",
    "    print(f\"Total de archivos analizados: {resultados['total_archivos']}\")\n",
    "    print(f\"Archivos con formato válido: {resultados['archivos_validos']}\")\n",
    "    print(f\"Archivos con formato inválido: {len(resultados['archivos_invalidos'])}\")\n",
    "    \n",
    "    if resultados['fecha_inicio'] and resultados['fecha_fin']:\n",
    "        print(f\"\\nFecha de inicio: {resultados['fecha_inicio'].strftime('%Y-%m-%d')}\")\n",
    "        print(f\"Fecha de fin: {resultados['fecha_fin'].strftime('%Y-%m-%d')}\")\n",
    "        rango_dias = (resultados['fecha_fin'] - resultados['fecha_inicio']).days + 1\n",
    "        print(f\"Rango total: {rango_dias} días\")\n",
    "    \n",
    "    if resultados['archivos_invalidos']:\n",
    "        print(\"\\nArchivos con formato inválido:\")\n",
    "        for archivo in resultados['archivos_invalidos']:\n",
    "            print(f\"  - {archivo}\")\n",
    "    \n",
    "    print(\"\\nDistribución de tipos de temperatura:\")\n",
    "    for tipo, cantidad in resultados['tipos_temperatura'].items():\n",
    "        print(f\"  - {tipo}: {cantidad}\")\n",
    "    \n",
    "    print(\"\\nVersiones encontradas:\")\n",
    "    for version, cantidad in resultados['versiones'].items():\n",
    "        print(f\"  - {version}: {cantidad}\")\n",
    "    \n",
    "    if resultados['fechas_incompletas']:\n",
    "        print(\"\\nFechas con archivos incompletos (menos de 3 tipos):\")\n",
    "        for fecha in sorted(resultados['fechas_incompletas']):\n",
    "            tipos = resultados['fechas'][fecha]['tipos']\n",
    "            print(f\"  - {fecha}: {len(tipos)} tipos - {', '.join(tipos)}\")\n",
    "    \n",
    "    if resultados['fechas_faltantes']:\n",
    "        print(\"\\nFechas faltantes:\")\n",
    "        for fecha in sorted(resultados['fechas_faltantes']):\n",
    "            print(f\"  - {fecha}\")\n",
    "    \n",
    "    if resultados['fechas_duplicadas']:\n",
    "        print(\"\\nFechas con más de 3 archivos:\")\n",
    "        for fecha in resultados['fechas_duplicadas']:\n",
    "            print(f\"  - {fecha}: {resultados['fechas'][fecha]['count']} archivos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4744f8df-51dd-4bce-85ee-32ac73374519",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informe de análisis de nombres de archivos:\n",
      "Total de archivos analizados: 48786\n",
      "Archivos con formato válido: 48786\n",
      "Archivos con formato inválido: 0\n",
      "\n",
      "Fecha de inicio: 1980-01-01\n",
      "Fecha de fin: 2024-07-09\n",
      "Rango total: 16262 días\n",
      "\n",
      "Distribución de tipos de temperatura:\n",
      "  - Temperature-Air-2m-Min-24h: 16262\n",
      "  - Temperature-Air-2m-Mean-24h: 16262\n",
      "  - Temperature-Air-2m-Max-24h: 16262\n",
      "\n",
      "Versiones encontradas:\n",
      "  - final-v1.1: 48774\n",
      "  - final-v1.1.1: 12\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    directorio = '/home/ec2-user/SageMaker/datalake/data/agera/temperature/landing'\n",
    "    resultados = analizar_nombres_archivos(directorio)\n",
    "    imprimir_informe(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec1591d9-8811-467b-b9f5-22c5977da4d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analizar_nombres_archivos2(directorio):\n",
    "    # Modificamos el patrón para aceptar versiones con uno o más dígitos después del punto\n",
    "    patron = re.compile(r'^(Temperature-Air-2m-(?:Min|Mean|Max)-24h)_(C3S-glob-agric)_(AgERA5)_(\\d{8})_(final-v\\d+\\.\\d+(?:\\.\\d+)?)\\.nc$')\n",
    "    \n",
    "    archivos = [f for f in os.listdir(directorio) if f.endswith('.nc')]\n",
    "    \n",
    "    resultados = {\n",
    "        'total_archivos': len(archivos),\n",
    "        'archivos_validos': 0,\n",
    "        'archivos_invalidos': [],\n",
    "        'tipos_temperatura': defaultdict(int),\n",
    "        'versiones': defaultdict(int),\n",
    "        'fechas': defaultdict(lambda: {'count': 0, 'tipos': set()}),\n",
    "        'fechas_faltantes': set(),\n",
    "        'fechas_incompletas': [],\n",
    "        'fechas_duplicadas': [],\n",
    "        'fecha_inicio': None,\n",
    "        'fecha_fin': None\n",
    "    }\n",
    "    \n",
    "    todas_las_fechas = set()\n",
    "    \n",
    "    for archivo in archivos:\n",
    "        match = patron.match(archivo)\n",
    "        if match:\n",
    "            resultados['archivos_validos'] += 1\n",
    "            tipo_temp, _, _, fecha, version = match.groups()\n",
    "            \n",
    "            fecha_dt = datetime.strptime(fecha, \"%Y%m%d\")\n",
    "            if resultados['fecha_inicio'] is None or fecha_dt < resultados['fecha_inicio']:\n",
    "                resultados['fecha_inicio'] = fecha_dt\n",
    "            if resultados['fecha_fin'] is None or fecha_dt > resultados['fecha_fin']:\n",
    "                resultados['fecha_fin'] = fecha_dt\n",
    "            \n",
    "            resultados['tipos_temperatura'][tipo_temp] += 1\n",
    "            resultados['versiones'][version] += 1\n",
    "            resultados['fechas'][fecha]['count'] += 1\n",
    "            resultados['fechas'][fecha]['tipos'].add(tipo_temp)\n",
    "            \n",
    "            todas_las_fechas.add(fecha)\n",
    "            \n",
    "            if resultados['fechas'][fecha]['count'] > 3:\n",
    "                resultados['fechas_duplicadas'].append(fecha)\n",
    "        else:\n",
    "            resultados['archivos_invalidos'].append(archivo)\n",
    "    \n",
    "    # Verificar fechas faltantes e incompletas\n",
    "    if resultados['fecha_inicio'] and resultados['fecha_fin']:\n",
    "        fecha_actual = resultados['fecha_inicio']\n",
    "        while fecha_actual <= resultados['fecha_fin']:\n",
    "            fecha_str = fecha_actual.strftime(\"%Y%m%d\")\n",
    "            if fecha_str not in todas_las_fechas:\n",
    "                resultados['fechas_faltantes'].add(fecha_str)\n",
    "            elif len(resultados['fechas'][fecha_str]['tipos']) < 3:\n",
    "                resultados['fechas_incompletas'].append(fecha_str)\n",
    "            fecha_actual += timedelta(days=1)\n",
    "    \n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4b20181-7452-4841-ae42-3a7a6776faf0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informe de análisis de nombres de archivos:\n",
      "Total de archivos analizados: 48786\n",
      "Archivos con formato válido: 48786\n",
      "Archivos con formato inválido: 0\n",
      "\n",
      "Fecha de inicio: 1980-01-01\n",
      "Fecha de fin: 2024-07-09\n",
      "Rango total: 16262 días\n",
      "\n",
      "Distribución de tipos de temperatura:\n",
      "  - Temperature-Air-2m-Min-24h: 16262\n",
      "  - Temperature-Air-2m-Mean-24h: 16262\n",
      "  - Temperature-Air-2m-Max-24h: 16262\n",
      "\n",
      "Versiones encontradas:\n",
      "  - final-v1.1: 48774\n",
      "  - final-v1.1.1: 12\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    directorio = '/home/ec2-user/SageMaker/datalake/data/agera/temperature/landing'\n",
    "    resultados = analizar_nombres_archivos2(directorio)\n",
    "    imprimir_informe(resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dfc84f-557c-4c70-8736-2f202e0bc967",
   "metadata": {},
   "source": [
    "## Sorted by dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1da9097e-5411-4c1a-9ae0-2e0b47016b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extraer_fecha_y_tipo(nombre_archivo):\n",
    "    match = re.search(r'Temperature-Air-2m-(Max|Mean|Min)-24h.*_(\\d{8})_', nombre_archivo)\n",
    "    if match:\n",
    "        tipo, fecha = match.groups()\n",
    "        return fecha, tipo\n",
    "    return '00000000', ''\n",
    "\n",
    "def ordenar_archivos(directorio):\n",
    "    archivos = [f for f in os.listdir(directorio) if f.endswith('.nc')]\n",
    "    archivos_por_fecha = defaultdict(dict)\n",
    "    for archivo in archivos:\n",
    "        fecha, tipo = extraer_fecha_y_tipo(archivo)\n",
    "        archivos_por_fecha[fecha][tipo] = archivo\n",
    "    fechas_ordenadas = sorted(archivos_por_fecha.keys())\n",
    "    archivos_ordenados = []\n",
    "    for fecha in fechas_ordenadas:\n",
    "        for tipo in ['Max', 'Mean', 'Min']:\n",
    "            if tipo in archivos_por_fecha[fecha]:\n",
    "                archivos_ordenados.append(archivos_por_fecha[fecha][tipo])\n",
    "    return archivos_ordenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b517373f-73c3-4652-a930-cd2718d14f63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "archivo = 'Temperature-Air-2m-Min-24h_C3S-glob-agric_AgERA5_20240131_final-v1.1.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f2a212d-a6e7-4dcb-b433-e3a98a560e76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "landing = '/home/ec2-user/SageMaker/datalake/data/agera/temperature/landing'\n",
    "test = '/home/ec2-user/SageMaker/datalake/data/agera/temperature/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc2d54e2-7a35-4db5-bc2c-334101dcb2c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Temperature-Air-2m-Max-24h_C3S-glob-agric_AgERA5_20240101_final-v1.1.nc'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordenar_archivos(test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2314e822-6746-425e-b886-958682f9f55a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25422146-d91f-4997-8a26-c0d4e9f6cec2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extraer_fecha_y_tipo(nombre_archivo):\n",
    "    match = re.search(r'Temperature-Air-2m-(Max|Mean|Min)-24h.*_(\\d{8})_', nombre_archivo)\n",
    "    if match:\n",
    "        tipo, fecha = match.groups()\n",
    "        return fecha, tipo\n",
    "    return '00000000', ''\n",
    "\n",
    "def ordenar_archivos(directorio):\n",
    "    archivos = [f for f in os.listdir(directorio) if f.endswith('.nc')]\n",
    "    archivos_por_fecha = defaultdict(lambda: {'Max': None, 'Mean': None, 'Min': None})\n",
    "    \n",
    "    for archivo in archivos:\n",
    "        fecha, tipo = extraer_fecha_y_tipo(archivo)\n",
    "        if fecha != '00000000' and tipo:\n",
    "            ruta_completa = os.path.join(directorio, archivo)\n",
    "            archivos_por_fecha[fecha][tipo] = ruta_completa\n",
    "    \n",
    "    # Convertir el defaultdict en un diccionario normal\n",
    "    archivos_por_fecha = dict(archivos_por_fecha)\n",
    "    \n",
    "    return archivos_por_fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe94e27-186b-4ebe-91bb-e0e940977f26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ordenar_archivos(ruta_local_entrada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d003077-ae7e-483b-bc6f-87534881d725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ruta_local_entrada = '/home/ec2-user/SageMaker/datalake/data/agera/temperature/test'\n",
    "bucket_salida = 'climate-action-datalake'\n",
    "ruta_salida_s3 = 'zone=raw/source=agera5-v1-1/variable=Temperature_Air_2m_24h.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02af421a-760e-4fb9-972f-ee16b5413c1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dfee639-7f4e-47fd-b346-6227cb35c7c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "todos_archivos = glob(os.path.join(ruta_local_entrada, '*.nc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ea3742-9d43-42ab-a77e-7d3de6adce75",
   "metadata": {},
   "source": [
    "## Desarrollo de Automatización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d812d011-6c86-4e75-8507-7ff0fa2f6d68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install luigi netCDF4 h5netcdf scipy dask[complete] boto3 s3fs numpy zarr pyyaml tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26cfb2e0-1086-49a2-99d7-7d87c1d03720",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install \"xarray[complete]\"==2023.8.0 s3fs --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "683ac8b5-bfb4-494b-b9be-0e81a2b8e730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install python-blosc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a18704-6965-4df1-9012-a1c22e69f559",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import s3fs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import os\n",
    "from glob import glob\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "import zarr\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a418599d-1155-46f0-b406-a2d075c98ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kelvin_a_celsius(temp_k):\n",
    "    return xr.where(np.isnan(temp_k), temp_k, temp_k - 273.15)\n",
    "\n",
    "def procesar_archivos_nc(ruta_local_entrada, bucket_salida, ruta_salida_s3):\n",
    "    # Patrones para los archivos de cada tipo de temperatura\n",
    "    patrones = {\n",
    "        'min': '*Min*.nc',\n",
    "        'mean': '*Mean*.nc',\n",
    "        'max': '*Max*.nc'\n",
    "    }\n",
    "    \n",
    "    datasets = []\n",
    "    \n",
    "    for tipo, patron in patrones.items():\n",
    "        archivos = glob(os.path.join(ruta_local_entrada, patron))\n",
    "        archivos.sort()  # Asegurar que los archivos estén en orden\n",
    "        \n",
    "        # Abrir todos los archivos de este tipo como un único dataset\n",
    "        ds = xr.open_mfdataset(archivos, combine='by_coords')\n",
    "        \n",
    "        # Convertir de Kelvin a Celsius\n",
    "        var_name = f'Temperature_Air_2m_{tipo.capitalize()}_24h'\n",
    "        ds[var_name] = kelvin_a_celsius(ds[var_name])\n",
    "        ds[var_name].attrs['units'] = 'C'\n",
    "        \n",
    "        datasets.append(ds)\n",
    "    \n",
    "    # Combinar todos los datasets\n",
    "    ds_final = xr.merge(datasets)\n",
    "    \n",
    "    # Configurar el sistema de archivos S3\n",
    "    s3 = s3fs.S3FileSystem(anon=False)\n",
    "    \n",
    "    # Escribir a Zarr en S3\n",
    "    zarr_store = s3fs.S3Map(root=f's3://{bucket_salida}/{ruta_salida_s3}', s3=s3)\n",
    "    ds_final.to_zarr(store=zarr_store, mode='a')\n",
    "    \n",
    "    print(f\"Datos procesados y guardados en S3: s3://{bucket_salida}/{ruta_salida_s3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9693c607-ec9d-40ff-bd07-94b6efac5954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arturo\n",
    "    compressor = zarr.Blosc(cname='lz4', clevel= 1, shuffle=False)\n",
    "    blosc.set_nthreads(8) \n",
    "    encoding = {vname: {'compressor': compressor,'chunks': (1,1,2000,7200)} for vname in nc.data_vars}\n",
    "    with ProgressBar():\n",
    "        #print(\"Hellooooo\")\n",
    "        nc.to_zarr(ageraS3,  mode='a', append_dim='time', consolidated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a828909-b3a3-4cba-b2dc-c886366e010b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zarr\n",
    "from dask.diagnostics import ProgressBar\n",
    "import s3fs\n",
    "import xarray as xr\n",
    "import os\n",
    "from glob import glob\n",
    "from numcodecs import blosc\n",
    "\n",
    "def kelvin_a_celsius(temp_kelvin):\n",
    "    return temp_kelvin - 273.15\n",
    "\n",
    "def procesar_archivos_nc(ruta_local_entrada, bucket_salida, ruta_salida_s3):\n",
    "    # Patrones para los archivos de cada tipo de temperatura\n",
    "    patrones = {\n",
    "        'min': '*Min*.nc',\n",
    "        'mean': '*Mean*.nc',\n",
    "        'max': '*Max*.nc'\n",
    "    }\n",
    "    \n",
    "    datasets = []\n",
    "    \n",
    "    for tipo, patron in patrones.items():\n",
    "        archivos = glob(os.path.join(ruta_local_entrada, patron))\n",
    "        archivos.sort()  # Asegurar que los archivos estén en orden temporal\n",
    "        \n",
    "        # Abrir todos los archivos de este tipo como un único dataset\n",
    "        ds = xr.open_mfdataset(archivos, combine='by_coords')\n",
    "        \n",
    "        # Convertir de Kelvin a Celsius\n",
    "        var_name = f'Temperature_Air_2m_{tipo.capitalize()}_24h'\n",
    "        ds[var_name] = kelvin_a_celsius(ds[var_name])\n",
    "        ds[var_name].attrs['units'] = 'C'\n",
    "        \n",
    "        datasets.append(ds)\n",
    "    \n",
    "    # Combinar todos los datasets\n",
    "    ds_final = xr.merge(datasets)\n",
    "    \n",
    "    # Configuración de la compresión y chunks para Zarr\n",
    "    compressor = zarr.Blosc(cname='lz4', clevel=1, shuffle=False)\n",
    "    blosc.set_nthreads(8)\n",
    "    \n",
    "    # Configuración de encoding para cada variable de datos\n",
    "    encoding = {var: {'compressor': compressor, 'chunks': (1, 1, 2000, 7200)} for var in ds_final.data_vars}\n",
    "    \n",
    "    # Configurar el sistema de archivos S3\n",
    "    s3 = s3fs.S3FileSystem(anon=False)\n",
    "    zarr_store = s3fs.S3Map(root=f's3://{bucket_salida}/{ruta_salida_s3}', s3=s3)\n",
    "    \n",
    "    # Escribir a Zarr en S3 con compresión y manejo de la dimensión temporal\n",
    "    with ProgressBar():\n",
    "        ds_final.to_zarr(zarr_store, mode='a', append_dim='time', consolidated=True, encoding=encoding)\n",
    "    \n",
    "    print(f\"Datos procesados y guardados en S3: s3://{bucket_salida}/{ruta_salida_s3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7a60c8-2c0e-4894-bdfa-1e642c1832eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ruta_local_entrada = '/home/ec2-user/SageMaker/datalake/data/agera/temperature/test'\n",
    "bucket_salida = 'climate-action-datalake'\n",
    "ruta_salida_s3 = 'zone=raw/source=agera5-v1-1/variable=Temperature_Air_2m_24h.zarr'\n",
    "\n",
    "procesar_archivos_nc(ruta_local_entrada, bucket_salida, ruta_salida_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3276b56-a2f1-47e1-bcad-12c22e29ffc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zarr\n",
    "from dask.diagnostics import ProgressBar\n",
    "import s3fs\n",
    "import xarray as xr\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from numcodecs import blosc\n",
    "\n",
    "def kelvin_a_celsius(temp_kelvin):\n",
    "    return temp_kelvin - 273.15\n",
    "\n",
    "def extraer_fecha_y_tipo(nombre_archivo):\n",
    "    match = re.search(r'Temperature-Air-2m-(Max|Mean|Min)-24h.*_(\\d{8})_', nombre_archivo)\n",
    "    if match:\n",
    "        tipo, fecha = match.groups()\n",
    "        return fecha, tipo\n",
    "    return '00000000', ''\n",
    "\n",
    "def ordenar_archivos(directorio):\n",
    "    archivos = [f for f in os.listdir(directorio) if f.endswith('.nc')]\n",
    "    archivos_por_fecha = defaultdict(lambda: {'Max': None, 'Mean': None, 'Min': None})\n",
    "    \n",
    "    for archivo in archivos:\n",
    "        fecha, tipo = extraer_fecha_y_tipo(archivo)\n",
    "        if fecha != '00000000' and tipo:\n",
    "            ruta_completa = os.path.join(directorio, archivo)\n",
    "            archivos_por_fecha[fecha][tipo] = ruta_completa\n",
    "    \n",
    "    return dict(archivos_por_fecha)\n",
    "\n",
    "def procesar_archivos_nc(ruta_local_entrada, bucket_salida, ruta_salida_s3, fecha_inicio, fecha_fin):\n",
    "    # Convert fecha_inicio and fecha_fin to strings if they are integers\n",
    "    fecha_inicio = str(fecha_inicio)\n",
    "    fecha_fin = str(fecha_fin)\n",
    "    \n",
    "    archivos_por_fecha = ordenar_archivos(ruta_local_entrada)\n",
    "    \n",
    "    # Filtrar fechas dentro del rango especificado\n",
    "    fechas_filtradas = {fecha: archivos for fecha, archivos in archivos_por_fecha.items()\n",
    "                        if fecha_inicio <= fecha <= fecha_fin}\n",
    "    \n",
    "    # Configurar el sistema de archivos S3\n",
    "    s3 = s3fs.S3FileSystem(anon=False)\n",
    "    zarr_store = s3fs.S3Map(root=f's3://{bucket_salida}/{ruta_salida_s3}', s3=s3)\n",
    "    \n",
    "    # Configuración de la compresión para Zarr\n",
    "    compressor = zarr.Blosc(cname='lz4', clevel=1, shuffle=False)\n",
    "    blosc.set_nthreads(8)\n",
    "    \n",
    "    for fecha, archivos in sorted(fechas_filtradas.items()):\n",
    "        print(f\"Procesando fecha: {fecha}\")\n",
    "        datasets = []\n",
    "        \n",
    "        for tipo, ruta_archivo in archivos.items():\n",
    "            if ruta_archivo is None:\n",
    "                print(f\"Advertencia: Falta archivo {tipo} para la fecha {fecha}\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                ds = xr.open_dataset(ruta_archivo)\n",
    "                var_name = f'Temperature_Air_2m_{tipo}_24h'\n",
    "                ds[var_name] = kelvin_a_celsius(ds[var_name])\n",
    "                ds[var_name].attrs['units'] = 'C'\n",
    "                datasets.append(ds)\n",
    "            except Exception as e:\n",
    "                print(f\"Error al procesar {ruta_archivo}: {str(e)}\")\n",
    "        \n",
    "        if not datasets:\n",
    "            print(f\"No se pudieron procesar datos para la fecha {fecha}\")\n",
    "            continue\n",
    "        \n",
    "        ds_dia = xr.merge(datasets)\n",
    "        \n",
    "        # Configurar encoding para cada variable\n",
    "        chunk_sizes = {dim: min(2000, len(ds_dia[dim])) for dim in ds_dia.dims}\n",
    "        encoding = {var: {'compressor': compressor, 'chunks': tuple(chunk_sizes[dim] for dim in ds_dia[var].dims)} \n",
    "                    for var in ds_dia.data_vars}\n",
    "        \n",
    "        # Escribir a Zarr en S3\n",
    "        with ProgressBar():\n",
    "            ds_dia.to_zarr(zarr_store, mode='a', append_dim='time', consolidated=True, encoding=encoding)\n",
    "        \n",
    "        print(f\"Datos para la fecha {fecha} procesados y guardados en S3\")\n",
    "    \n",
    "    print(f\"Todos los datos procesados y guardados en S3: s3://{bucket_salida}/{ruta_salida_s3}\")\n",
    "\n",
    "def main():\n",
    "    ruta_local_entrada = '/home/ec2-user/SageMaker/datalake/data/agera/temperature/landing'\n",
    "    bucket_salida = 'climate-action-datalake'\n",
    "    ruta_salida_s3 = 'zone=raw/source=agera5-v1-1/variable=Temperature_Air_2m_24h.zarr'\n",
    "    \n",
    "    # Solicitar al usuario las fechas de inicio y fin\n",
    "    fecha_inicio = input(\"Ingrese la fecha de inicio (YYYYMMDD): \")\n",
    "    fecha_fin = input(\"Ingrese la fecha de fin (YYYYMMDD): \")\n",
    "    \n",
    "    # Procesar los archivos\n",
    "    procesar_archivos_nc(ruta_local_entrada, bucket_salida, ruta_salida_s3, fecha_inicio, fecha_fin)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5a5b3e5-a3c5-4002-af00-32b2969c304c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:                      (time: 17, lat: 1801, lon: 3600)\n",
      "Coordinates:\n",
      "  * lat                          (lat) float64 90.0 89.9 89.8 ... -89.9 -90.0\n",
      "  * lon                          (lon) float64 -180.0 -179.9 ... 179.8 179.9\n",
      "  * time                         (time) datetime64[ns] 2024-01-01 ... 2024-01-17\n",
      "Data variables:\n",
      "    Temperature_Air_2m_Max_24h   (time, lat, lon) float32 dask.array<chunksize=(1, 226, 900), meta=np.ndarray>\n",
      "    Temperature_Air_2m_Mean_24h  (time, lat, lon) float32 dask.array<chunksize=(1, 226, 900), meta=np.ndarray>\n",
      "    Temperature_Air_2m_Min_24h   (time, lat, lon) float32 dask.array<chunksize=(1, 226, 900), meta=np.ndarray>\n",
      "Attributes:\n",
      "    Conventions:  CF-1.7\n"
     ]
    }
   ],
   "source": [
    "# Configurar la conexión a S3\n",
    "s3 = s3fs.S3FileSystem(anon=False)\n",
    "\n",
    "# Especificar la ubicación del archivo Zarr en S3\n",
    "bucket_name = 'climate-action-datalake'\n",
    "zarr_path = 'zone=raw/source=agera5-v1-1/variable=Temperature_Air_2m_24h.zarr'\n",
    "s3_url = f's3://{bucket_name}/{zarr_path}'\n",
    "\n",
    "# Abrir el archivo Zarr\n",
    "ds = xr.open_zarr(s3fs.S3Map(s3_url, s3=s3))\n",
    "\n",
    "# Mostrar información básica sobre el dataset\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64059302-1e24-403f-b480-b2da603e2a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c78612-9ee8-411d-8695-53740975fa43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Procesar los archivos\n",
    "ruta_local_entrada = '/home/ec2-user/SageMaker/datalake/data/agera/temperature/test'\n",
    "bucket_salida = 'climate-action-datalake'\n",
    "ruta_salida_s3 = 'zone=raw/source=agera5-v1-1/variable=Temperature_Air_2m_24h.zarr'\n",
    "fecha_inicio = 19800101\n",
    "fecha_fin = 19800131\n",
    "procesar_archivos_nc(ruta_local_entrada, bucket_salida, ruta_salida_s3, fecha_inicio, fecha_fin)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
