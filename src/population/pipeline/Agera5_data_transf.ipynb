{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a99ed78b-6b7a-468d-b8f5-33bbcda1301a",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ab1e68-f849-4119-b458-335c92924cc2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install rioxarray \"xarray[complete]\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1c63766-f625-4cbc-9e97-fa0be77c9c3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Libraries import\n",
    "import xarray as xr\n",
    "import s3fs\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import multiprocessing\n",
    "import fsspec\n",
    "import boto3\n",
    "import numpy as np\n",
    "import rioxarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b70bfec-d82c-4150-aa7b-6d4ad5d94f8d",
   "metadata": {},
   "source": [
    "## General functions (They can be executed for very variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5be5ae5-04ef-4e8b-832e-cd2666d67c45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upload_files(files, s3, file_name, bucket_name, s3_file_key):\n",
    "    \n",
    "    \"\"\"\n",
    "    Uploads NetCDF files to an AWS S3 bucket.\n",
    "\n",
    "    This function saves a given xarray Dataset to a local file in NetCDF format,\n",
    "    uploads the file to the specified S3 bucket, and then removes the local file.\n",
    "\n",
    "    Parameters:\n",
    "    files (xarray.Dataset): The NetCDF datasets to be saved and uploaded.\n",
    "    s3 (boto3.session.Session.client): The S3 client used for uploading files.\n",
    "    local_file_path (str): The path where the NetCDF file will be saved locally.\n",
    "    bucket_name (str): The name of the S3 bucket to upload the file to.\n",
    "    s3_file_key (str): The S3 path and name under which the file will be stored.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    files.to_netcdf(file_name, engine='h5netcdf', format='NETCDF4')\n",
    "    s3.upload_file(file_name, bucket_name, s3_file_key)\n",
    "    os.remove(file_name)\n",
    "    print(f'File {file_name} uploaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d5b6015-715c-4405-8fe9-9c69345471b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def file_exists_in_bucket(bucket_name, folder_path, file_name, s3_client):\n",
    "    \"\"\"\n",
    "    Checks if a file exists in an S3 bucket.\n",
    "    \n",
    "    This function attempts to retrieve metadata from the specified file\n",
    "    in the given S3 bucket and returns True if the file exists, otherwise False.\n",
    "\n",
    "    Parameters:\n",
    "    s3_client (boto3.session.Session.client): The S3 client used for accessing the bucket.\n",
    "    bucket_name (str): The name of the S3 bucket.\n",
    "    folder_path (str): The path to the folder within the S3 bucket.\n",
    "    file_name (str): The name of the file to check for existence (includig extension).\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the file exists, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        s3_client.head_object(Bucket=bucket_name, Key=os.path.join(folder_path, file_name))\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ca53db-a9ed-417c-a6f0-4438add343df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_data(nc, res, bbox, file_name, s3_file_key, bucket_name, s3_client):\n",
    "    \n",
    "    \"\"\"\n",
    "    Resamples and crops a NetCDF dataset and uploads the processed file to an S3 bucket.\n",
    "\n",
    "    This function resamples a NetCDF to a specified resolution using bilinear interpolation, \n",
    "    crops it to a bounding box,and uploads the processed data to an S3 bucket.\n",
    "\n",
    "    Parameters:\n",
    "    nc (xarray.Dataset): The NetCDF to be processed.\n",
    "    res (float): The target resolution.\n",
    "    bbox (tuple): The bounding box to crop the data to as (min_lon, min_lat, max_lon, max_lat).\n",
    "    file_name (str): The name of the NetCDF file.\n",
    "    s3_file_key (str): The S3 key under which the file will be stored in the bucket (path and name).\n",
    "    bucket_name (str): The name of the S3 bucket to upload the file to.\n",
    "    s3_client (boto3.session.Session.client): The S3 client used for uploading files.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    #Assign CRS to the data\n",
    "    nc.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "    \n",
    "    # Resample the data to the new resolution using bilinear interpolation\n",
    "    resampled_data = nc.rio.reproject(\"EPSG:4326\", resolution=res, resampling=2)\n",
    "    \n",
    "    # Crop the resampled data to the bounding box\n",
    "    cropped_data = resampled_data.rio.clip_box(*bbox)\n",
    "    \n",
    "    #Rename coordinates\n",
    "    cropped_data = cropped_data.rename({'x': 'lon', 'y': 'lat'})\n",
    "\n",
    "    #Upload the processed data to the bucket\n",
    "    upload_files(files = cropped_data\n",
    "                 ,s3 = s3_client\n",
    "                 ,file_name = file_name\n",
    "                 ,bucket_name = bucket_name\n",
    "                 ,s3_file_key = s3_file_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02442b20-7416-4a64-9cc8-e287e9747357",
   "metadata": {},
   "source": [
    "## To process temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f78f83a1-f7df-4d75-a21c-bfe241d64454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_kelvin_to_celsius(nc_files, bucket_name, folder_path, s3):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function opens a NetCDF temperature file from an S3 bucket, converts the temperature data\n",
    "    from Kelvin to Celsius (excluding NaN values), do the resample and clip process and upload tthe\n",
    "    processed data to another S3 bucket.\n",
    "\n",
    "    Parameters:\n",
    "    nc_files (str): The S3 path to the NetCDF file.\n",
    "    bucket_name (str): The name of the S3 bucket to upload the file to.\n",
    "    folder_path (str): The folder path within the S3 bucket to upload the data.\n",
    "    s3 (s3fs.S3FileSystem): The S3 file system object used for accessing the S3 bucket.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    #Set up the folders \n",
    "    s3_path = \"s3://\" + nc_files\n",
    "    file_name = os.path.basename(nc_files)\n",
    "    s3_file_key = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # Initialize S3 boto client with explicit credentials\n",
    "    s3_client = boto3.client('s3',\n",
    "                      aws_access_key_id='AKIATHPVGK3ZVLVSHEEF',\n",
    "                      aws_secret_access_key='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',\n",
    "                      region_name='us-west-2')\n",
    "    \n",
    "    # Check if the file already exists in the bucket\n",
    "    if file_exists_in_bucket(bucket_name, folder_path, file_name, s3_client):\n",
    "        print(f\"File {nc_files} already exists in the bucket. Skipping process.\")\n",
    "        return None  \n",
    "    \n",
    "    else:\n",
    "        print(f\"File {nc_files} do not exists in the bucket. Starting process.\")\n",
    "        \n",
    "        with s3.open(s3_path) as fileObj:\n",
    "            # Open and do the conversion from Kelvin to Celsius just in not NA values\n",
    "            nc =  xr.open_dataset(fileObj, engine='h5netcdf')\n",
    "            temp = nc['Temperature_Air_2m_Min_24h']\n",
    "            temp.values[~np.isnan(temp)] = temp.values[non_na_mask] - 273.15\n",
    "            \n",
    "            #Regrid and clip the nc to a certain resolution and bounding \n",
    "            resample_data(nc = nc\n",
    "                          ,res = 0.05\n",
    "                          ,bbox =  (-180, -50, 180, 50)\n",
    "                          ,file_name = file_name\n",
    "                          ,s3_file_key = s3_file_key\n",
    "                          ,bucket_name = bucket_name\n",
    "                          ,s3_client = s3_client)\n",
    "            #Close the nc\n",
    "            nc.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5500de0a-9848-479f-8de5-23712ea5882b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "###### Test ###############\n",
    "\n",
    "s3 = s3fs.S3FileSystem(key='AKIATHPVGK3ZVLVSHEEF',secret='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')\n",
    "\n",
    "#Temperature folder in the bucket\n",
    "folder = \"s3://climate-action-datalake/zone=landing/source=agera5/variable=2mTemperature/\"\n",
    "\n",
    "# List files\n",
    "files = s3.ls(folder)\n",
    "\n",
    "# Define the pattern to match\n",
    "pattern = re.compile(r'.*-Min-.*\\.nc')\n",
    "\n",
    "# Find files with the matching pattern\n",
    "matching_files = [file for file in files if pattern.match(file)]\n",
    "\n",
    "bucket_name = 'climate-action-datalake'\n",
    "folder_path = 'zone=temporal/source=agera5/variable=airTemperatureMin/'\n",
    "\n",
    "arguments = [(nc_files, 0.05, (-180, -50, 180, 50),  bucket_name, folder_path, s3) for nc_files in matching_files]\n",
    "\n",
    "with multiprocessing.Pool(20) as pool:\n",
    "            results = pool.starmap(convert_kelvin_to_celsius, arguments)\n",
    "print('Finished')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
